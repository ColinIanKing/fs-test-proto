#!/usr/bin/python
#
# Copyright (C) 2014 Canonical, Ltd.
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
#
# Author: Colin Ian King <colin.king@canonical.com>
#
import os
import sys
import stat
import json
import numpy as np
import re
import gzip
import string
import errno
import operator

default_colors = [ '#ff0000', '#00ff00', '#0000ff' ]
#
# Default graph sizes in pixels
#
default_width = 1000
default_height = 500
default_max_plots_in_scatter_plot = 1500

job_config_cache = {}

if len(sys.argv) < 2:
	sys.exit('Usage: %s results-path' % sys.argv[0])

if not os.path.exists(sys.argv[1]):
	sys.exit('Path %s not found' % sys.argv[1])

#
#  generate a html file containing links to graphs
#
def generate_html(html_subdirs, html, root_path, sub_path, html_file, title):
	page = '''
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <script type="text/javascript" src="https://www.google.com/jsapi"></script>
  <meta content="text/html; charset=ISO-8859-1"
 http-equiv="content-type">
  <title>''' + title + '''</title>
  <h2><center>''' + title + '''</center></h2>'''
	page += '''
</head>
<body>
<center>
  <table width=100% cellspacing="2">
'''
	colors = [ "#ffffff", "#e0f0ff" ]
	i = 0
	for (t, f) in sorted(html_subdirs, key=lambda d: d[0]):
		common = os.path.commonprefix([sub_path, f])
		relname = f[len(common)+1:]
		page += '\n    <tr><td><center><a href="' + relname + '">' + t + '</a></center></td></tr>'
	page += html

	for f in sorted(os.listdir(sub_path)):
		(filename, extension) = os.path.splitext(f)
		if extension == ".png":
			page += '\n <tr><td bgcolor="' + colors[i % 2] + '"><center><img src=' + f + '></center></td></tr>'
			i += 1
	page += '''
  </table>
</center>
</body>
</html>'''
	mkdirp(sub_path)
	filename = os.path.join(sub_path, "index.html")
	f = open(filename, 'w')
	f.write(page)
	f.close()
	return (title, filename)

#
#  fio data log mappings
#
#
samples_info = [
	#  key		human readable title			regex on log name	generated filename path
	('Bandwidth',	'Bandwidth KB per second',	'job.*_bw\.log*', 	'daily-fio-stats-bandwidth'),
	('IOops',	'I/O ops per second', 		'job.*_iops\.log*', 	'daily-fio-stats-io-ops'),
	('IOLatency',	'I/O Latency (us)', 		'job.*_lat\.log*', 	'daily-fio-stats-io-latency'),
	('IOCLatencty',	'I/O Completion Latency (us)',	'job.*_clat\.log*', 	'daily-fio-stats-clatency') ]

#
#  Create all dirs in a given path
#
def mkdirp(path):
	try:
		os.makedirs(path)
	except OSError as exc:
		if exc.errno == errno.EEXIST and os.path.isdir(path):
			pass
		else: raise

#
#  Load sysinfo
#
def sysinfo_load(file):
	sysinfo = {}

	if os.path.isfile(file):
		f = open(file, 'r')
	else:
		f = gzip.open(file + '.gz')

	for line in f.read().splitlines():
		if ':' in line:
			[key, val] = line.split(':',1)
			sysinfo[key] = val.lstrip()
	f.close()
	return sysinfo

#
#  Get and cache job configuration data
#
def job_config_get(job):
	config = []
	keys = [ 'Label', 'Units', 'Scale', 'JsonPath' ]
	if job in job_config_cache:
		return job_config_cache[job]
	else:
		f = open(os.path.join('jobs', job + '.conf'), 'r')
		for line in f.read().splitlines():
			if line[:1] == '#':
				continue
			if not "," in line:
				continue
			info = {}
			fields = line.split(',', 4)
			if ',' in line:
				for i in range(0, len(fields)):
					info[keys[i]] = fields[i].lstrip().rstrip()

			config.append(info)
		f.close()
		job_config_cache[job] = config
		return config

#
#  Variants of keys?
#
def keys_variant_collection(part_stats):
	skipkeys = [ 'Fiostats', 'Datapath', 'Samples', 'Time-run','Time', 'Kernel-version', 'Full Date']
	keys = set([])
	for stats in part_stats:
		for sysinfo1 in stats:
			for sysinfo2 in stats:
				for key in sysinfo2:
					try:
						if not key in skipkeys and sysinfo1[key] != sysinfo2[key]:
							keys.add(key)
					except:
						pass
	return list(keys)

#
#  Remove trailing comma and spaces from label
#
def clean_label(label):
	str = label
	while str.endswith(' ') or str.endswith(','):
		str = str[:-2]
	return str

#
#  Take an array of words and return words as a comma separated string
#
def array_to_str(array):
	return ', '.join(array)

#
#  keys in sysinfo to a label
#
def sysinfo_keys_to_label(sysinfo, keys):
	return ', '.join([ sysinfo[key] for key in keys if key in sysinfo ])

#
#  Convert a string into a filename containing letters and digits
#
def str_to_filename(str):
	filename = ''
	for c in str.lower():
		if c in string.ascii_letters or c in string.digits:
			filename += c
		else:
			filename += '-'

	return filename

#
#  horizontal bar chart
#
def bar_horiz(html_subdirs, root_path, keys, config, collection):
	title = config['Label']
	units = config['Units']
	print "Graphing " + title
	#
	#  Filename based on title..
	#
	filename = str_to_filename(title)
	newpath = os.path.join(root_path, filename)
	mkdirp(newpath)
	#
	#  Sort collection on xlabel
	#
	collection = sorted(collection, key=lambda d: d[3])
	#
	#  Collect up end labels, see how many there are and
	#  this allows us to determine how to color the bars
	#
	endlabels = set([])
	for (subtitle, xlabels, yvalues, xlabel, sysinfos) in collection:
		endlabels = endlabels.union({ l.split()[::-1][0] for l in xlabels })
	endlabels = sorted(endlabels)

	html = ""
	n = 0
	for c in collection:
		(subtitle, xlabels, yvalues, xlabel, sysinfos) = c
		xvalues = [ xlabels.index(x) for x in xlabels ]
		#
		#  And sort values in x order (sigh)
		#
		indexes = np.argsort(xlabels)[::-1]

		html += '''
	<script type="text/javascript">
	google.load("visualization", "1", {packages:["corechart"]});
	google.setOnLoadCallback(drawChart);
	function drawChart() {
        var data = google.visualization.arrayToDataTable([
	'''
		html += "['Filesytem', '" + title + " (" + units + ")'," + \
			" { role: 'style' }],\n"

		for i in indexes:
			end = xlabels[i].split()[::-1][0]
			html += "['" + xlabels[i] + "', " + str(yvalues[i]) + "," + \
			"'fill-color: " + default_colors[endlabels.index(end)] + "; " + \
			"fill-opacity: 0.9'],\n"

		html += "]);\n"
		html += '''
        var options = {
          title: ' ''' + xlabel + ": " + title + " (" + units + ") " + subtitle + ''' ',
          vAxis: {title: 'Configuration' },
          hAxis: {title: ' ''' + title + " (" + units + ")" + ''' ', minValue: 0 },
	  legend: {position: 'none' }
        };

        var chart = new google.visualization.BarChart(document.getElementById('chart_div'));
        chart.draw(data, options);
      }
	</script>
	<div id="chart_div" style="width: ''' + str(default_width) + '''px; height: ''' + str(default_width) + '''px;"></div>'''

	html_subdirs.append(generate_html([], html, root_path, newpath, filename, title))

#
#  trend line graph plot
#
def plot_horiz_trend(html_subdirs, path, keys, config, collection):
	title = config['Label']
	units = config['Units']

	#
	# Determine all the xlabels in the collection
	# and collect up unique filesystems and ioscheds
	#
	filesystems = set([])
	ioscheds = set([])
	all_xlabels = set([])
	for (subtitle, xlabels, yvalues, xlabel, sysinfos) in collection:
		all_xlabels = all_xlabels.union({ xlabel for xlabel in xlabels })
		filesystems = filesystems.union({ sysinfo['Filesystem'] for sysinfo in sysinfos })
		ioscheds = ioscheds.union({ sysinfo['IO Scheduler'] for sysinfo in sysinfos })

	all_xlabels = sorted(all_xlabels)
	ioscheds = sorted(ioscheds)
	filesystems = sorted(filesystems)

	new_path = os.path.join(path, str_to_filename(title))
	mkdirp(new_path)

	chart = 0
	html = ""

	for io in ioscheds:
		html += '''
	<script type="text/javascript">
	google.load("visualization", "1", {packages:["corechart"]});
	google.setOnLoadCallback(drawChart);
	function drawChart() {
        var data = google.visualization.arrayToDataTable([
	'''
		html += "['Run #' "
		for fs in filesystems:
			html += ", '" + fs + "'"
		html += "],\n"

		for xl in all_xlabels:
			html += "[ '" + xl + "' "
			values = {}
			for fs in filesystems:
				values = " null "
				for (subtitle, xlabels, yvalues, xlabel, sysinfos) in collection:
					sysinfo = sysinfos[0]
					if sysinfo['Filesystem'] == fs and \
					   sysinfo['IO Scheduler'] == io and \
					   xl in xlabels:
						index = xlabels.index(xl)
						values = str(yvalues[index])
				html += "," + values
			html += "],\n"

		html += "]);\n"
		html += '''
        var options = {
          title: ' ''' + io + ": " + title + " (" + units + ") " + subtitle + ''' ',
          hAxis: {title: 'Run #' },
          vAxis: {title: ' ''' + title + " (" + units + ")" + ''' ', minValue: 0  },
	  interpolateNulls: true,
	  pointShape: 'diamond',
	  pointSize: 4
        };

        var chart = new google.visualization.AreaChart(document.getElementById(''' + "'chart_div_" + io + "'" + '''));
        chart.draw(data, options);
      }
	</script>
	<div id="chart_div_''' + io + '''" style="width: ''' + str(default_width) + '''px; height: ''' + str(default_height) + '''px;"></div>'''

	html_subdirs.append(generate_html([], html, new_path, new_path, title, title))

#
#  Calculate heatmap colors
#
def heatmap_colors(heatmap):
	max_val = 0
	for datarow in heatmap:
		max_val = max(max_val, max(datarow))

	#
	# Create a range of colours 0..max_val
	#
	max_val += 1
	red = float(255)
	green = float(0)
	step = 2 * (float(255) / max_val)
	colors = []

	while green < 255:
		green += step
		green = min(green, 255)
		color = (65536 * int(red)) + (256 * int(green))
		colors.append(format(color, '06x'))

	while red > 0:
		red -= step
		red = max(red, 0)
		color = (65536 * int(red)) + (256 * int(green))
		colors.append(format(color, '06x'))

	return colors[::-1]

#
#  Calculate moving average of data with a specificed window size
#
def moving_average(values, window):
    weights = np.repeat(1.0, window)/window
    return np.convolve(values, weights, 'valid')


#
#  plot samples and heatmaps from raw fio data
#
def plot_samples_raw_fio_data(root_path, key, keys, title, sysinfos):
	title_keys = ['Job', 'Filesystem', 'Kernel-release']

	html = ""
	chart = 0

	filesystems = sorted({ sysinfo['Filesystem'] for sysinfo in sysinfos })
	ioscheds = sorted({ sysinfo['IO Scheduler'] for sysinfo in sysinfos })

	#
	# Part #1, histogram of means
	#
	mean_y = []
	vticks = []
	for fs in filesystems:
		for io in ioscheds:
			for sysinfo in sysinfos:
				if sysinfo['Filesystem'] == fs and sysinfo['IO Scheduler'] == io:
					samples = sysinfo['Samples'][key]
					total_y = 0
					total_n = 0
					for (x, y) in samples:
						total_y += sum(y)
						total_n += len(y)
	
					if total_n != 0:
						mean_y.append(float(total_y) / total_n)
					else:
						mean_y.append(0)
					vticks.append(io + ' ' + fs)

	nbars = len(vticks)
	#
	# normally fit in ~9 bars + some extra 1 bars slack for headings etc
	#
	new_height = (nbars + 1) * (default_height / 10)

	html += '''
	<script type="text/javascript">
	google.load("visualization", "1", {packages:["corechart"]});
	google.setOnLoadCallback(drawChart);
	function drawChart() {
        var data = google.visualization.arrayToDataTable([
	'''

	html += "['Filesytem', '" + title + "'," + \
		" { role: 'style' }],\n"

	for i in range(0, len(mean_y)):
		fs = vticks[i].split()[::-1][0]
		html += "['" + vticks[i] + "', " + str(mean_y[i]) + "," + \
			"'fill-color: " + default_colors[filesystems.index(fs)] + "; " + \
			"fill-opacity: 0.9'],\n"

	html += "]);\n"
	html += '''
        var options = {
          title: 'Mean ''' + title + ''' ',
          vAxis: {title: 'Configuration' },
          hAxis: {title: 'Mean ''' + title + ''' ', minValue: 0 },
	  legend: {position: 'none' }
        };

        var chart = new google.visualization.BarChart(document.getElementById('chart_div_hist'));
        chart.draw(data, options);
      }
	</script>
	<div id="chart_div_hist" style="width: ''' + str(default_width) + '''px; height: ''' + str(new_height) + '''px;"></div>'''

	#
	# Now do scatter plot and heat maps
	#
	for fs in sorted(filesystems):
		for io in sorted(ioscheds):
			for sysinfo in sysinfos:
				subtitle = ""
				for k in title_keys:
					if not k in keys:
						subtitle += sysinfo[k] + ", "

				if sysinfo['Filesystem'] == fs and sysinfo['IO Scheduler'] == io:
					samples = sysinfo['Samples'][key]
					max_x = 0
					max_y = 0
					all_x = []
					all_y = []
					#
					#  Data is bundled in 1 or more sets of results
					#  For scatter plot and heatmap we can combine
					#  it all into one big hunk of data
					#
					for (x, y) in samples:
						all_x += x
						all_y += y

					max_y = max(all_y)
					max_x = max(all_x)
					avg_y = moving_average(all_y, len(all_y) / 20)

					rows=32
					cols=64
					tick_interval = 5
					heatmap, yedges, xedges = np.histogram2d(all_y, all_x, bins=(rows,cols))

					rows_delta = float(max_y) / float(tick_interval - 1)
					cols_delta = float(max_x) / float(tick_interval)
					heatmap_vticks = []
					for k in range(0, tick_interval + 1):
						heatmap_vticks.append("{v:" + str(k * float(rows)/tick_interval) + ", f:'" + str(k * float(max_y)/tick_interval) + "'}")
					heatmap_hticks = []
					for k in range(0, tick_interval + 1):
						heatmap_hticks.append("{v:" + str(k * float(cols)/tick_interval) + ", f:'" + str(k * float(max_x)/tick_interval) + "'}")
					vticks = []
					for k in range(0, tick_interval + 1):
						vticks.append("{v:" + str(k * float(max_y)/tick_interval) + ", f:'" + str(k * float(max_y)/tick_interval) + "'}")
					hticks = []
					for k in range(0, tick_interval + 1):
						hticks.append("{v:" + str(k * float(max_x)/tick_interval) + ", f:'" + str(k * float(max_x)/tick_interval) + "'}")

					n = len(all_y)
					mean_y = float(sum(all_y)) / n
					skip = float(n) / float(default_max_plots_in_scatter_plot)
					if skip > 1:
						all_x = [ all_x[int(r)] for r in np.arange(0, len(all_x) - 1, skip)]
						all_y = [ all_y[int(r)] for r in np.arange(0, len(all_y) - 1, skip)]
						avg_y = [ avg_y[int(r)] for r in np.arange(0, len(avg_y) - 1, skip)]
					html += '''
<html>
  <head>
    <script type="text/javascript" src="http://www.google.com/jsapi"></script>
    <script type="text/javascript">
      google.load("visualization", "1", {});
      google.load("prototype", "1.6");
    </script>
    <script type="text/javascript">
      google.load("visualization", "1", {packages:["corechart"]});
      google.setOnLoadCallback(drawChart);
      function drawChart() {
        var data = google.visualization.arrayToDataTable([
['Sample #','Value', 'Rolling Average', 'Mean'],
'''
					n_avg_y = len(avg_y)
					offset = (len(all_y) - n_avg_y) / 2
					mean_y = str(mean_y)
					for k in range(0,len(all_y)):
						if k >= offset and (k - offset) < n_avg_y:
							avg = str(avg_y[k - offset])
						else:
							avg = "null"
						html += "[" + str(all_x[k]) + "," + str(all_y[k]) + "," + avg + "," + mean_y +"],\n"

					html += '''
	]);

        var options = {
          title: ''' + "'" + subtitle + sysinfo_keys_to_label(sysinfo, keys) + "'" + ''',
          legend: { position: 'right' },
          pointSize: 0.1,
	  width: 500,
	  height: 300,
	  hAxis: { ticks:[''' + ','.join(hticks) + '''], title:'Sample #' },
	  vAxis: { ticks:[''' + ','.join(vticks) + '''], title:''' "'" + title + "'" +''' },
        };

        var chart = new google.visualization.ScatterChart(document.getElementById(''' + \
		"'chart_div_scatter_" + str(chart) + "'" + '''));

        chart.draw(data, options);
      }
    </script>
    <script type="text/javascript">
      google.load("visualization", "1", {packages:["corechart"]});
      google.setOnLoadCallback(drawChart);
      function drawChart() {
        var data = google.visualization.arrayToDataTable([
['Sample #','Value',{ role: 'style'}],
'''
					colors = heatmap_colors(heatmap)
					row=0
					for datarow in heatmap:
						col = 0
						for d in datarow:
							html += "[" + str(col + 0.5)  + "," + str(row + 0.5) + ",'color:#" + colors[int(d)] + "'],"
							col += 1
						row += 1

					html += '''
	]);

        var options = {
          title: ''' + "'" + subtitle + sysinfo_keys_to_label(sysinfo, keys) + "'" + ''',
	  pointShape: 'square',
	  pointSize: 6,
          legend: 'none',
	  hAxis: { ticks:[''' + ','.join(heatmap_hticks) + '''], title:'Sample #' },
	  vAxis: { ticks:[''' + ','.join(heatmap_vticks) + '''], title:''' "'" + title + "'" +''' },
	  width: 500,
	  height: 300,
	  tooltip: { trigger: 'none' }
        };

        var chart = new google.visualization.ScatterChart(document.getElementById(''' + \
		"'chart_div_heatmap_" + str(chart) + "'" + '''));
        chart.draw(data, options);
      }
    </script>
    <table>
    <tr>
      <td>
        <div id="chart_div_scatter_''' + str(chart) + '''"></div>
      </td>
      <td>
        <div id="chart_div_heatmap_''' + str(chart) + '''"></div>
      </td>
    <tr>
    </table>
'''
					chart += 1

	return html

#
#  Traverse a path to find json values
#
def get_json_val(json_data, fullpath):
	path = fullpath.split('.')
	j = json_data
	try:
		for p in path:
			if p.isdigit():
				j = j[int(p)]
			else:
				j = j[p]
		return j
 	except:
		return 0


#
# Do statistic data gathering
#
def graph_stats(html_subdirs, root_path, graph_func, stats_collection, collection_keys):
	#
	# Determine which jobs were run
	# and hence all the unique configs
	#
	unique_configs = []
	keys = keys_variant_collection(stats_collection)

	for stats in stats_collection:
		for sysinfo in stats:
			job = sysinfo['Job']
			config = job_config_get(job)
			for c in config:
				if not c in unique_configs:
					unique_configs.append(c)

	#
	#  The following are config values that we may be
	#  interested in labelling
	#
	sysinfokeys = [ 'Blocksize', 'Filesystem', 'Device', 'Hardware',
		       	'Job', 'Kernel-release', 'Date', 'Filesize', 'Processor', 'IO Scheduler' ]
	#
	#   gather the data
	#
	for config in unique_configs:
		sysinfovals = {}
		collection = []
		#
		#  find all the different sysinfo fields that change and don't
		#  change across the tests
		#
		for stats in stats_collection:
			for sysinfo in stats:
				if config in job_config_get(sysinfo['Job']):
					for c in sysinfokeys:
						try:
							if not sysinfo[c] in sysinfovals[c]:
								sysinfovals[c].append(sysinfo[c])
						except:
							sysinfovals[c] = [sysinfo[c]]
		sysinfo_fields_vary = []
		sysinfo_fields_static = []
		for s in sysinfovals:
			if len(sysinfovals[s]) > 1:
				if not s in collection_keys:
					sysinfo_fields_vary.append(s)
			else:
				sysinfo_fields_static.append(s)

		#
		# And sort them in sysinfokey order
		#
		sysinfo_fields_vary = sorted(sysinfo_fields_vary, key = lambda x:sysinfokeys.index(x))
		sysinfo_fields_static = sorted(sysinfo_fields_static, key = lambda x:sysinfokeys.index(x))

		label = config['Label']
		units = config['Units']
		scale = float(config['Scale'])
		jsonpath = config['JsonPath']
		subtitle = [ sysinfo[f] for f in sysinfo_fields_static ]

		for stats in stats_collection:
			yvalues = []
			xlabels = []
			sysinfos = []
			for sysinfo in stats:
				if config in job_config_get(sysinfo['Job']):
					val = get_json_val(sysinfo['Fiostats'], jsonpath)
					yvalues.append(val / scale)
					xlabel = ""
					for f in sysinfo_fields_vary:
						xlabel += sysinfo[f] + ", "

					xlabels.append(clean_label(xlabel))
					sysinfos.append(sysinfo)

					for c in sysinfokeys:
						try:
							if not sysinfo[c] in sysinfovals[c]:
								sysinfovals[c].append(sysinfo[c])
						except:
							sysinfovals[c] = [sysinfo[c]]
				xlabel = []
				for f in collection_keys:
					xlabel.append(sysinfo[f])
			#
			# Add them to the subplot collection
			#
			if len(xlabels) > 0:
				collection.append((array_to_str(subtitle), xlabels, yvalues, array_to_str(xlabel), sysinfos))

		graph_func(html_subdirs, root_path, keys, config, collection)

#
#  Load in fio-stats.json and sysinfo.log for the given tests
#
def collect_stats(path):
	stats = []
	for datapath, _dirs, files in os.walk(path):
		head, tail = os.path.split(datapath)
		if tail == "stats":
			sysinfo = sysinfo_load(os.path.join(datapath, 'sysinfo.log'))
			job_config_get(sysinfo['Job'])

			sysinfo['Samples'] = None	# Loaded on demand later
			sysinfo['Datapath'] = datapath

			try:
				f = open(os.path.join(datapath, 'fio-stats.json'), 'r')
				sysinfo['Fiostats'] = json.load(f)
				f.close()
				stats.append(sysinfo)
			except:
				print "Failed to read fio-stats.json for " + datapath

	return stats

#
#  Given a set of criteria, find all the gathered stats that match
#
def find_matching_stats(stats, criteria):
	matches = []
	for sysinfo in stats:
		keep = True
		for (key, values) in criteria:
			if values != []:
				found = False
				for value in values:
					if key in sysinfo and sysinfo[key] == value:
						found = True
						break
				keep = keep and found
		if keep:
			matches.append(sysinfo)

	return matches

def find_unique_key_value_stats(stats, criteria, key):
	values = []
        matches = find_matching_stats(stats, criteria)
	for sysinfo in matches:
		if not sysinfo[key] in values:
			values.append(sysinfo[key])

	print "Found %d unique stats" % len(values)
	return values

#
#  Load samples given a path and a regex pattern for the
#  raw data name.  Loads fio raw samples.
#
def samples_load_by_pattern(path, pattern):
	regex = re.compile(pattern)
	values = []
	for l in sorted(os.listdir(path)):
		for m in [regex.search(l)]:
			if m:
				filename = os.path.join(path, l)
				if filename[-3:] == '.gz':
					f = gzip.open(filename)
				else:
					f = open(filename, 'r')

				lines = f.readlines()
				f.close()
				x = [ int(col.split(',')[0]) for col in lines]
				y = [ int(col.split(',')[1]) for col in lines]
				values.append((x,y))
	return values

#
#  Load samples from file from a given path
#
def samples_load(path):
	print "Loading data: " + path
	samples = {}
	for (key, title, pattern, name) in samples_info:
		samples[key] = samples_load_by_pattern(path, pattern)

	return samples

def graph_samples(html_subdirs, root_path, path, key, stats, keys, title):
	#
	# Find all unique jobs
	#
	jobs = sorted({ sysinfo['Job'] for sysinfo in stats})
	#
	# Process data from each unique job:
	#
	html = ""
	for job in jobs:
		print "Graphing " + title + " (" + job + ")"
		ordered_stats = []
		titles = []
		for sysinfo in stats:
			if sysinfo['Job'] == job:
				if sysinfo['Samples'] == None:
					sysinfo['Samples'] = samples_load(sysinfo['Datapath'])
				samples = sysinfo['Samples']
				ordered_stats.append(sysinfo)
				titles.append(sysinfo_keys_to_label(sysinfo, keys))
		#
		# Sort based on the chart titles
		#
		indexes = np.argsort(titles)
		titles = [ titles[i] for i in indexes ]
		ordered_stats = [ ordered_stats[i] for i in indexes ]

		new_path = os.path.join(path, job)
		mkdirp(new_path)

		if len(ordered_stats):
			html = plot_samples_raw_fio_data(new_path, key, keys, title, ordered_stats)
			html_subdirs.append(generate_html([], html, root_path, new_path, job, job))
		else:
			print "No relevant data can be found"

	return html

#
#  break stats into collections based on the group_by_keys
#
def compare_stats_ordered_traverse(graph_func, stats, group_by_keys, collection_keys, traversed_stats):
	if (len(group_by_keys) <= 1):
		sortstats = sorted(stats, key = lambda d: d[group_by_keys[0]])
		traversed_stats.append(sortstats)
		return
	#
	#  For all key values, partition into "collections"
	#  where the key value is identical and sub-divide
	#  or graph on next key value
	#
	k = group_by_keys[0]
	suborder_by_keys = group_by_keys[1:len(group_by_keys)]

	if not k in collection_keys:
		compare_stats_ordered_traverse(graph_func, stats, suborder_by_keys, collection_keys, traversed_stats)
	else:
		values = set([])
		for sysinfo in stats:
			values.add(sysinfo[k])

		for v in values:
			substats = [ sysinfo for sysinfo in stats if sysinfo[k] == v ]
			compare_stats_ordered_traverse(graph_func, substats, suborder_by_keys, collection_keys, traversed_stats)

#
#  group up data by group_by_keys and then graph it using graph_func
#
def compare_stats_ordered(html_subdirs, path, graph_func, stats, group_by_keys, collection_keys):
	traversed_stats = []
	compare_stats_ordered_traverse(graph_func, stats, group_by_keys, collection_keys, traversed_stats)
	graph_stats(html_subdirs, path, graph_func, traversed_stats, collection_keys)


#
#  Histogram of fs + tests on a given day
#
def daily_tests_histogram(html_dirs, root_path, date):
	tests = find_matching_stats(stats, 
		[
			('Date', date),
			('Job', []),
			('Filesystem', []),
			('Kernel-release', []),
			('IO Scheduler', [])
		])
	#
	# Compare filesystems
	#
	newpath = os.path.join(root_path, 'daily-fio-histograms-by-filesystem')
	mkdirp(newpath)
	html_subdirs = []
	compare_stats_ordered(html_subdirs, newpath, bar_horiz, tests,
		['IO Scheduler', 'Job', 'Filesystem', 'Date' ], ['Job'])
	html_dirs.append(generate_html(html_subdirs, "", root_path, newpath, 'daily-tests-histogram', 'Fio Test Metrics (by metric) ' + ', '.join(date)))

#
#  Samples of fs on a given day
#
def daily_tests_samples(html_dirs, root_path, date):
	tests = find_matching_stats(stats,
		[
			('Date', date),
			('Job', []),
			('Filesystem', []),
			('Kernel-release', [])
		])
	keys = keys_variant_collection([tests])
	#
	#  Process raw samples from fio logs
	#
	for (key, title, pattern, name) in samples_info:
		new_path = os.path.join(root_path, name)
		mkdirp(new_path)
		html_subdirs = []
		graph_samples(html_subdirs, root_path, new_path, key, tests, keys, title)
		html_dirs.append(generate_html(html_subdirs, "", root_path, new_path, name, title + ": " + ', '.join(date)))

#
#  Plot trends over time
#
def overtime_trends(html_dirs, root_path):
	new_path = os.path.join(root_path, 'overtime-trends')
	mkdirp(new_path)

	kernel_release = []
	file_systems = []
	date = []

	jobs = find_unique_key_value_stats(stats,
		[
			('Date', date),
			('Job', []),
			('Filesystem', file_systems),
			('Kernel-release', kernel_release)
		], 'Job')

	html_subdirs = []
	for job in jobs:
		html_jobsubdirs = []
		print "Generating trends for job " + job
		job_path = os.path.join(new_path, job)
		mkdirp(job_path)
		tests = find_matching_stats(stats, 
			[
				('Date', date),
				('Job', [job]),
				('Filesystem', file_systems),
				('Kernel-release', kernel_release )
			])
		compare_stats_ordered(html_jobsubdirs, job_path, plot_horiz_trend, tests,
			[ 'Job', 'Filesystem', 'IO Scheduler', 'Kernel-release'], ['Filesystem', 'IO Scheduler', 'Job'])
		html_subdirs.append(generate_html(html_jobsubdirs, "", new_path, job_path, 'overtime-trends', job + ": " + 'trends over time'))

	html_dirs.append(generate_html(html_subdirs, "", root_path, new_path, 'overtime-trends', 'All trends over time'))

#
#  Gather up stats
#
dates = ['2014-07-16' ]
html_dirs = []
stats = []
tmpdir = "/tmp/test"
print "Results in " + tmpdir

print "Reading metadata.."
for i in range(1, len(sys.argv)):
	stats += collect_stats(sys.argv[i])

mkdirp(tmpdir)

daily_tests_histogram(html_dirs, tmpdir, dates)
#daily_tests_samples(html_dirs, tmpdir, dates)
#overtime_trends(html_dirs, tmpdir)

generate_html(html_dirs, "", tmpdir, tmpdir, 'results', 'All results')
