#!/usr/bin/python
#
# Copyright (C) 2014 Canonical, Ltd.
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
#
# Author: Colin Ian King <colin.king@canonical.com>
#
import os
import sys
import json
import numpy as np
import matplotlib.pyplot as plt
import re
import gzip
import tempfile
import string
import errno

if len(sys.argv) < 2:
	sys.exit('Usage: %s results-path' % sys.argv[0])

if not os.path.exists(sys.argv[1]):
	sys.exit('Path %s not found' % sys.argv[1])

import os, errno

def mkdirp(path):
	try:
		os.makedirs(path)
	except OSError as exc:
		if exc.errno == errno.EEXIST and os.path.isdir(path):
			pass
		else: raise

#
#  Load sysinfo
#
def sysinfo_load(file):
	sysinfo = {}

	if os.path.isfile(file):
		f = open(file, 'r')
	else:
		f = gzip.open(file + '.gz')

	for line in f.read().splitlines():
		if ':' in line:
			[key, val] = line.split(':',1)
			sysinfo[key] = val.lstrip()
	f.close()

	return sysinfo

job_config_cache = {}

#
#  Get and cache job configuration data
#
def job_config_get(job):
	config = []
	keys = [ 'Label', 'Units', 'Scale', 'JsonPath' ]
	if job in job_config_cache:
		return job_config_cache[job]
	else:
		f = open(os.path.join('jobs', job + '.conf'), 'r')
		for line in f.read().splitlines():
			if line[:1] == '#':
				continue
			info = {}
			fields = line.split(',', 4)
			if ',' in line:
				for i in range(0, len(fields)):
					info[keys[i]] = fields[i].lstrip().rstrip()

			config.append(info)
		f.close()
		job_config_cache[job] = config
		return config

#
#  Variants of keys?
#
def keys_variant(stats):
	skipkeys = [ 'Time', 'Kernel-version', 'Full Date']
	keys = []
	for (cur, sysinfo1, fio_stats) in stats:
		for (cur, sysinfo2, fio_stats) in stats:
			for key in sysinfo2:
				if not key in keys and not key in skipkeys and sysinfo1[key] != sysinfo2[key]:
					keys.append(key)

	return keys

#
#
#
def clean_label(label):
	str = label
	while str.endswith(' ') or str.endswith(','):
		str = str[:-2]
	return str

#
#  Take an array of words and return words as a comma separated string
#
def array_to_str(array):
	#  Must be a better way to do this
	str = ""
	for a in array:
		if str != "":
			str = str + ", "
		str = str + a
	return str

def sysinfo_keys_to_title(sysinfo, keys):
	return array_to_str(keys)

def sysinfo_keys_to_label(sysinfo, keys):
	label = ""
	for key in keys:
		if label != "":
			label = label + ", "
		label = label + sysinfo[key]
	return label

def save_png(path, title, fig):
	str = ''
	for c in title.lower():
		if c in string.ascii_letters:
			str += c
		else:
			str += '-'

	filename = os.path.join(path, str + ".png")
	fig.savefig(filename, dpi=70)
	return filename

#
#  Very simple horizontal bar chart
# 
def bar_horiz(path, keys, config, collection):
	title = config['Label']
	units = config['Units']

	nplots = len(collection)
	fig, plots = plt.subplots(nplots, figsize=(8, 1.5 * nplots + 1))
	colors ='rgbwmc'

	#
	#  Sort collection on xlabel
	#
	collection = sorted(collection, key=lambda d: d[3])

	#
	#  Determine all the xlabels in the collection
	#
	all_xlabels = []
	ymax = 0
	ymin = 1e12
	for c in collection:
		(subtitle, xlabels, yvalues, xlabel) = c
		for xlabel in xlabels:
			if not xlabel in all_xlabels:
				all_xlabels.append(xlabel)
		ymax = max(ymax, max(yvalues))
		ymin = min(ymin, min(yvalues))

	all_xlabels = sorted(all_xlabels, reverse=True)
	
	(subtitle, xlabels, yvalues, xlabel) = collection[0]

	j = 0
	for c in collection:
		(subtitle, xlabels, yvalues, xlabel) = c

		xvalues = []
		for x in xlabels:
			xvalues.append(xlabels.index(x))

		#
		#  And sort values in x order (sigh)
		#
		indexes = np.argsort(xlabels)[::-1]
		xlabels = [ xlabels[i] for i in indexes ]
		yvalues = [ yvalues[i] for i in indexes ]
		pos = range(1, len(xlabels)+1, 1)

		plots[j].xaxis.grid(True, which='both')
		plots[j].barh(pos, yvalues, align='center', color=colors)
		plots[j].set_title(xlabel + "," + title + " (" + units + ")" + "\n" + subtitle)

		fig.sca(plots[j])
		plt.yticks(pos, xlabels)
		j = j + 1

	plt.tight_layout()
	save_png(path, title, fig)



#
#  Very simple graph plot
# 
def plot_horiz(path, keys, config, collection):
	title = config['Label']
	units = config['Units']

	fig, plot = plt.subplots(figsize=(8, 8))

	#
	#  Determine all the xlabels in the collection
	#
	all_xlabels = []
	ymax = 0
	ymin = 1e12
	for c in collection:
		(subtitle, xlabels, yvalues, xlabel) = c
		for xlabel in xlabels:
			if not xlabel in all_xlabels:
				all_xlabels.append(xlabel)
		ymax = max(ymax, max(yvalues))
		ymin = min(ymin, min(yvalues))

	(subtitle, xlabels, yvalues, xlabel) = collection[0]

	for c in collection:
		(subtitle, xlabels, yvalues, xlabel) = c

		xvalues = []
		for x in xlabels:
			xvalues.append(all_xlabels.index(x))

		#
		#  And sort vales in x order (sigh)
		#
		indexes = np.argsort(xvalues)
		xvalues = [ xvalues[i] for i in indexes ]
		yvalues = [ yvalues[i] for i in indexes ]

		plot.plot(xvalues, yvalues, label = xlabel)
		plot.grid(True)
		plot.set_xticklabels(all_xlabels, rotation=90)
		plot.set_xlabel(subtitle)
		plot.set_ylabel(title + " (" + units + ")")
		plot.set_ylim(ymin * 0.95, ymax * 1.20)
		plot.set_xlim(0, len(all_xlabels) -1)
	plt.title(title)
	plt.legend(loc = 1, prop={'size':10})
	plt.tight_layout()
	#plt.show()
	save_png(path, title, fig)

def plot_samples_by_filesystem_cols(path, keys, title, data):
	title_keys = ['Job', 'Filesystem', 'Kernel-release']
	cols = []
	for (values, sysinfo) in data:
		if not sysinfo['Filesystem'] in cols:
			cols.append(sysinfo['Filesystem'])

	nplots = len(data)
	ncols = len(cols)
	nrows = nplots / ncols

	fig, plots = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols,  3 * nrows))

	max_y = 0
	#
	#  Calculate some simple stats
	#
	for (values, sysinfo) in data:
		total_y = 0
		total_n = 0
		for (x, y) in values:
			max_y = max(max_y, max(y))
			total_y += sum(y)
			total_n += len(y)
		if total_n == 0:
			sysinfo['mean_y'] = 0
		else:
			sysinfo['mean_y'] = float(total_y) / total_n

	subtitle = ""
	for k in title_keys:
		if not k in keys:
			subtitle += sysinfo[k] + ", "

	n = 0
	for (values, sysinfo) in data:
		fs = sysinfo['Filesystem']
		i = n % nrows
		j = n / nrows
		
		for (x, y) in values:
			max_x = max(x)
			max_y = max(y)
			plots[i,j].plot(x, y, '.', color='black')
			plots[i,j].set_xlabel('Sample #')
			plots[i,j].set_ylabel(title)
			plots[i,j].set_title(title + '\n' + subtitle + sysinfo_keys_to_label(sysinfo, keys))
			plots[i,j].set_xlim(0, max_x)
			plots[i,j].set_ylim(0, max_y * 1.15)
			plots[i,j].yaxis.grid(True, which='both')

		yy = sysinfo['mean_y']
		fs = sysinfo['Filesystem']
		x = [0, max_x ]
		y = [yy, yy]
		plots[i,j].plot(x, y, label='Mean ' + '%.4f' % yy, color='red')
		plots[i,j].legend(loc = 1, prop={'size':10})
		n = n + 1

	plt.tight_layout()
	#plt.show()
	save_png(path, title, fig)
	return


def plot_samples(path, keys, title, data):
	nplots = len(data)
	title_keys = ['Job', 'Filesystem', 'Kernel-release']

	fig, plots = plt.subplots(nrows=nplots, figsize=(7, nplots * 3))

	i = 0
	max_y = 0
	#
	#  Calculate some simple stats
	#
	for (values, sysinfo) in data:
		total_y = 0
		total_n = 0
		for (x, y) in values:
			max_y = max(max_y, max(y))
			total_y += sum(y)
			total_n += len(y)
		if total_n == 0:
			sysinfo['mean_y'] = 0
		else:
			sysinfo['mean_y'] = float(total_y) / total_n

	subtitle = ""
	for k in title_keys:
		if not k in keys:
			subtitle += sysinfo[k] + ", "

	for (values, sysinfo) in data:
		fs = sysinfo['Filesystem']
		
		for (x, y) in values:
			max_x = max(x)
			plots[i].plot(x, y, '.', color='black')
			plots[i].set_xlabel('Sample #')
			plots[i].set_ylabel(title)
			plots[i].set_title(title + ', ' + subtitle + sysinfo_keys_to_label(sysinfo, keys))
			plots[i].set_xlim(0, max_x)
			plots[i].yaxis.grid(True, which='both')

		yy = sysinfo['mean_y']
		fs = sysinfo['Filesystem']
		x = [0, max_x ]
		y = [yy, yy]
		plots[i].plot(x, y, label='Mean ' + '%.4f' % yy, color='red')
		plots[i].legend(loc = 2)
		i = i + 1

	plt.tight_layout()
	#plt.show()
	save_png(path, title, fig)
	return

#
#  Traverse a path to find json values
#
def get_json_val(json_data, fullpath):
	path = fullpath.split('.')
	j = json_data
	try:
		for p in path:
			if p.isdigit():
				j = j[int(p)]
			else:
				j = j[p]
		return j
 	except:
		return 0


#
# Do statistic data gathering
#
def compare_stats(path, graph_func, stats_collection, keys, stacked_keys):
	#
	# Determine which jobs were run
	# and hence all the unique configs
	#
	unique_configs = []

	for stats in stats_collection:
		for (cur, sysinfo, fio_stats) in stats:
			job = sysinfo['Job']
			config = job_config_get(job)
			for c in config:
				if not c in unique_configs:
					unique_configs.append(c)

	#
	#  The following are config values that we may be
	#  interested in in labelling
	#
	sysinfokeys = [ 'Blocksize', 'Filesystem', 'Device', 'Hardware',
		       	'Job', 'Date', 'Kernel-release', 'Filesize', 'Processor' ]

	#
	#  Step #1, find all the different sysinfo fields that change
	#  across all the collections and tests
	#	
	sysinfovals = {}
	collection_fields_vary = []
	for config in unique_configs:
		for stats in stats_collection:
			for (cur, sysinfo, fio_stats) in stats:
				if config in job_config_get(sysinfo['Job']):
					for c in sysinfokeys:
						try:
							if not sysinfo[c] in sysinfovals[c]:
								sysinfovals[c].append(sysinfo[c])
						except:
							sysinfovals[c] = [ sysinfo[c] ]

	for s in sysinfovals:
		if len(sysinfovals[s]) > 1:
			collection_fields_vary.append(s)

	#
	#  Step #2, gather the data
	#
	for config in unique_configs:
		sysinfovals = {}
		collection = []

		#
		#  find all the different sysinfo fields that change and don't
		#  change across the tests
		#
		for stats in stats_collection:
			for (cur, sysinfo, fio_stats) in stats:
				if config in job_config_get(sysinfo['Job']):
					for c in sysinfokeys:
						try:
							if not sysinfo[c] in sysinfovals[c]:
								sysinfovals[c].append(sysinfo[c])
						except:
							sysinfovals[c] = [sysinfo[c]]

		sysinfo_fields_vary = []
		sysinfo_fields_static = []

		for s in sysinfovals:
			if len(sysinfovals[s]) > 1:
				if not s in stacked_keys:
					sysinfo_fields_vary.append(s)
			else:
				sysinfo_fields_static.append(s)

		label = config['Label']
		units = config['Units']
		scale = float(config['Scale'])
		jsonpath = config['JsonPath']

		subtitle = []
		for f in sysinfo_fields_static:
			subtitle.append(sysinfo[f])

		for stats in stats_collection:
			yvalues = []
			xlabels = []
			for (cur, sysinfo, fio_stats) in stats:
				if config in job_config_get(sysinfo['Job']):
					val = get_json_val(fio_stats, jsonpath)
					yvalues.append(val / scale)
					xlabel = ""
					for f in sysinfo_fields_vary:
						xlabel += sysinfo[f] + ", "

					xlabels.append(clean_label(xlabel))

					for c in sysinfokeys:
						try:
							if not sysinfo[c] in sysinfovals[c]:
								sysinfovals[c].append(sysinfo[c])
						except:
							sysinfovals[c] = [sysinfo[c]]
			

				xlabel = []
				for f in stacked_keys:
					xlabel.append(sysinfo[f])
			
			#
			# Add them to the subplot collection
			#
			collection.append((array_to_str(subtitle), xlabels, yvalues, array_to_str(xlabel)))

		graph_func(path, keys, config, collection)

#
#  Load in fio-stats.json and sysinfo.log for the given tests
#
def collect_stats(path):
	stats = []
	for cur, _dirs, files in os.walk(path):
		head, tail = os.path.split(cur)
		if tail == "stats":
			sysinfo   = sysinfo_load(os.path.join(cur, 'sysinfo.log'))
			f = open(os.path.join(cur, 'fio-stats.json'), 'r')
			fio_stats = json.load(f)
			f.close()
			stats.append((cur, sysinfo, fio_stats))
			job_config_get(sysinfo['Job'])
	return stats

def find_matching_stats(stats, criteria):
	matches = []
	for (cur, sysinfo, fio_stats) in stats:
		keep = True
		for (key, values) in criteria:
			if values != []:
				found = False
				for value in values:
					if key in sysinfo and sysinfo[key] == value:
						found = True
						break
				keep = keep and found
		if keep:
			print "Got " + cur
			matches.append((cur, sysinfo, fio_stats))

	return matches

def compare_samples(path, stats, keys, title, pattern):
	regex = re.compile(pattern)
	data = []
	titles = []
	for (cur, sysinfo, fio_stats) in stats:
		values = []
		for l in sorted(os.listdir(cur)):
			x = []
			y = []
			for m in [regex.search(l)]:
				if m:
					filename = os.path.join(cur, l)
					if filename[-3:] == '.gz':
						f = gzip.open(filename)
					else:
						f = open(filename, 'r')
					for line in f.read().splitlines():
						s = line.split(',')
						x.append(int(s[0]))
						y.append(int(s[1]))
					f.close()
					values.append((x,y))
		data.append((values, sysinfo))
		titles.append(sysinfo_keys_to_label(sysinfo, keys))
	#
	# Sort based on the chart titles
	#
	indexes = np.argsort(titles)
	titles = [ titles[i] for i in indexes ]
	data = [ data[i] for i in indexes ]

	if len(data):
		plot_samples_by_filesystem_cols(path, keys, title, data)
	else:
		print "No relevant data can be found"

def compare_stats_ordered_traverse(graph_func, stats, keys, order, stacked_keys, traversed_stats):
	if (len(order) <= 1):
		sortstats = sorted(stats, key=lambda d: d[1][order[0]])
		traversed_stats.append(sortstats)

		print "Collection:"
		for (cur, sysinfo, fio_stats) in sortstats:
			print cur
		return

	#
	#  For all key values, partition into groups
	#  where the key value is identical and sub-divide
	#  or graph on next key value
	#
	k = order[0]
	suborder = order[1:len(order)]

	if not k in stacked_keys:
		compare_stats_ordered_traverse(graph_func, stats, keys, suborder, stacked_keys, traversed_stats)
	else:
		values = []
		for (cur, sysinfo, fio_stats) in stats:
			if not sysinfo[k] in values:
				values.append(sysinfo[k])
		for v in values:
			substats = []
			for s in stats:
				(cur, sysinfo, fio_stats) = s
				if sysinfo[k] == v:
					substats.append(s)

			compare_stats_ordered_traverse(graph_func, substats, keys, suborder, stacked_keys, traversed_stats)


def compare_stats_ordered(path, graph_func, stats, keys, order, stacked_keys):
	traversed_stats = []
	compare_stats_ordered_traverse(graph_func, stats, keys, order, stacked_keys, traversed_stats)
	compare_stats(path, graph_func, traversed_stats, keys, stacked_keys)


def generate_html(path, html_file, title):
	page = '''
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html; charset=ISO-8859-1"
 http-equiv="content-type">
  <title>''' + title + '''</title>
  <h2><center>''' + title + '''</center></h2>'''


	page += '''
</head>
<body>'''

	for l in sorted(os.listdir(path)):
		(filename, extension) = os.path.splitext(l)
		if extension == ".png":
			page += '\n  <img src=' + l + '><br><br>'
	page += '''
</body>
</html>''' 

	mkdirp(path)
		
	f = open(os.path.join(path, html_file + ".html"), 'w')
	f.write(page)
	f.close()

	return
	

#
#  Histogram of fs + tests on a given day
#
def daily_tests_histogram(path, date):
	tests = find_matching_stats(stats, [ ('Date', [date]), ('Job', []), ('Filesystem', []), ('Kernel-release', [])])
	keys = keys_variant(tests)

	#
	# Compare filesystems
	#
	newpath = os.path.join(path, 'daily-fio-histograms-by-filesystem')
	mkdirp(newpath)
	compare_stats_ordered(newpath, bar_horiz, tests, keys, ['Job', 'Filesystem', 'Date'], ['Job'])
	generate_html(newpath, 'daily-tests-histogram', 'Test run on ' + date)

	#
	# Compare tests
	#
	newpath = os.path.join(path, 'daily-fio-histograms-by-test')
	mkdirp(newpath)
	compare_stats_ordered(newpath, bar_horiz, tests, keys, ['Filesystem', 'Date'], ['Filesystem'])
	generate_html(newpath, 'daily-tests-histogram', 'Test run on ' + date)
#
#  Samples of fs on a given day
# 
def daily_tests_samples(path, date):
	tests = find_matching_stats(stats, [ ('Date', [date]), ('Job', []), ('Filesystem', []), ('Kernel-release', [])])
	keys = keys_variant(tests)

	graphs = [
		('Bandwidth',	'job.*_bw\.log*', 'daily-fio-stats-bandwidth'),
		('I/O ops per sec', 'job.*_iops\.log*', 'daily-fio-stats-io-ops'),
		('I/O Latency', 'job.*_lat\.log*', 'daily-fio-stats-io-latency'),
		('I/O Completion Latency ', 'job.*_clat\.log*', 'daily-fio-stats-clatency') ]

	for g in graphs:
		newpath = os.path.join(path, g[2])
		mkdirp(newpath)
		compare_samples(newpath, tests, keys, g[0], g[1])
		generate_html(newpath, g[2], 'Test run on ' + date)


#
#  Plot trends over time 
#
def overtime_trends(path):
	newpath = os.path.join(path, 'overtime-trends')
	mkdirp(newpath)

	tests = find_matching_stats(stats, [ ('Date', []), ('Job', ['write-sync-rand-4']), ('Filesystem', []), ('Kernel-release', [])])
	keys = keys_variant(tests)
	compare_stats_ordered(newpath, plot_horiz, tests, keys, ['Job', 'Filesystem', 'Date'], ['Filesystem', 'Job'])
	generate_html(newpath, 'overtime-trends', 'Trends over time')

#
#  Gather up stats
#
stats = []
for i in range(1, len(sys.argv)):
	stats += collect_stats(sys.argv[i])


tmpdir = tempfile.mkdtemp()
tmpdir = "/tmp/test"
print "results in " + tmpdir

daily_tests_histogram(tmpdir, '2014-06-23')
overtime_trends(tmpdir)
daily_tests_samples(tmpdir, '2014-06-23')






